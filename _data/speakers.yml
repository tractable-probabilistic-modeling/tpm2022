speakers:
  - name: Elizaveta Semenova
    surname: Semenova
    url: https://scholar.google.com/citations?user=jqGIgFEAAAAJ
    affiliation: University of Oxford, UK
    title: Encoding spatial priors with VAEs for geospatial modelling
    img: liza.jpeg
    abstract: "Gaussian processes (GPs), implemented through multivariate Gaussian distributions for a finite collection of data, are the most popular approach in spatial statistical modelling. In this context they are used to encode correlation structures over space and can generalise well in interpolation tasks. Despite their flexibility, off-the-shelf GPs present serious computational challenges which limit their scalability and practical usefulness in applied settings. I will present a deep generative modelling approach to tackle this challenge: for a particular spatial setting, a class of GP priors is approximated through prior sampling and subsequent training of a variational autoencoder (VAE). Given a trained VAE, the resultant decoder allows spatial inference to become incredibly efficient due to the low dimensional, independently distributed latent Gaussian space representation of the VAE. Once trained, inference using the VAE decoder replaces the GP within a Bayesian sampling framework. This approach provides tractable and easy-to-implement means of approximately encoding spatial priors and facilitates efficient statistical inference."
    bio: Liza is currently a postdoctoral research associate at the University of Oxford where she works on scalable methods and flexible models for spatiotemporal data. More broadly, interests lie at the intersection of Bayesian statistics and such applied fields as epidemiology, public policy and drug discovery.
  
  - name: Rianne van den Berg
    surname: Berg
    url: https://www.microsoft.com/en-us/research/people/rvandenberg/
    affiliation: Microsoft Research
    title: Generative models for discrete random variables and lossless source compression
    abstract: In this talk I will discuss how different classes of generative models can be adapted to handle discrete random variables, and how this can be used to connect generative models to downstream tasks such as lossless compression. I will start by discussing normalizing flow models, and the challenges that arise when converting these models that are typically designed for real-valued random variables to discrete random variables. Next, I will demonstrate how denoising diffusion models with discrete state spaces have a rich design space in terms of the noising process, and how this influences the performance of the learned denoising model. Finally, I will show how denoising diffusion models can be connected to autoregressive models, and introduce an autoregressive model with a random generation order.
    bio: TBA
    img: rianne.png

  - name: Baharan Mirzasoleiman
    surname: Mirzasoleiman
    url: https://web.cs.ucla.edu/~baharan/
    affiliation: UCLA, USA
    title: Efficient and Robust Learning from Massive Datasets
    abstract: Large datasets have been crucial to the success of modern machine learning models. However, training on massive data has two major limitations. First, it is contingent on exceptionally large and expensive computational resources, and incurs a substantial cost due to the significant energy consumption. Second, in many real-world applications such as medical diagnosis, self-driving cars, and fraud detection, big data contains highly imbalanced classes and noisy labels. In such cases, training on the entire data does not result in a high-quality model. In this talk, I will argue that we can address the above limitations by developing techniques that can identify and extract the most informative subsets for learning from massive datasets. Training on such subsets not only reduces the substantial costs of learning from big data, but also improves their accuracy and robustness against noisy labels. I will discuss how we can develop effective and theoretically rigorous techniques that provide strong guarantees for the learned modelsâ€™ quality and robustness against noisy labels.
    bio: TBA
    img: baharan.png

  - name: Adji Bousso Dieng
    surname: Dieng
    url: https://engineering.princeton.edu/faculty/adji-bousso-dieng
    affiliation: Princeton, USA
    title: TBA
    abstract: TBA
    bio: "Adji Bousso Dieng is an Assistant Professor of Computer Science at Princeton University where she leads Vertaix on research at the intersection of artificial intelligence and the natural sciences. She is also a Research Scientist at Google AI and the founder and President of the nonprofit The Africa I Know. She has recently been named the Annie T. Randall Innovator of 2022 for her research and advocacy. She received her Ph.D. from Columbia University and was advised by David Blei and John Paisley. Her doctoral work received many recognitions, including a Google Ph.D. Fellowship in Machine Learning, a rising star in Machine Learning nomination, and the Savage Award."
    img: dieng.jpeg
    
  - name: Vibhav Gogate
    surname: Gogate
    url: https://cs.utdallas.edu/people/faculty/gogate-vibhav/
    affiliation: UT Dallas, USA
    title: TBA
    abstract: TBA
    bio: TBA
    img: gogate.jpg

  - name: Vikash K. Mansinghka
    surname: Mansinghka
    url: http://probcomp.csail.mit.edu/principal-investigator/
    affiliation: MIT, USA
    title: TBA
    abstract: TBA
    bio: TBA
    img: vikash.png
    